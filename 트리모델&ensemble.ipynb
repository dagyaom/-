{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "트리모델&ensemble.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYCSnArAnWYx8az+G49h5L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dagyaom/Python_Practice/blob/main/%ED%8A%B8%EB%A6%AC%EB%AA%A8%EB%8D%B8%26ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vtuERVW5s0x"
      },
      "source": [
        "# 결정트리(Decision Trees)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg3JcvQDIFGu"
      },
      "source": [
        "## Merge사용한 데이터 불러오기\n",
        "- 나누어진 feature와 target을 합한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv5AzGOx-00v"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mi4aIq2-q2m"
      },
      "source": [
        "train_1 = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train.csv')\n",
        "train_1.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXmA69Yv-zSR"
      },
      "source": [
        "train_2 = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train_labels.csv')\n",
        "train_2.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLSiZt_d5rEK"
      },
      "source": [
        "# 데이터 가져오기\n",
        "target = 'vacc_h1n1_f'\n",
        "train1 = pd.merge(pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train.csv'),\n",
        "                 pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train_labels.csv')[target], left_index=True, right_index=True)\n",
        "train1.head(3)\n",
        "\n",
        "# 왼쪽 데이터프레임의 인덱스를 조인키로 사용함."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_KuCTUX_RM3"
      },
      "source": [
        "test = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/test.csv')\n",
        "test.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XQOnGqOH7Vp"
      },
      "source": [
        "sample_submission = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/submission.csv')\n",
        "sample_submission.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DmCHugHILyi"
      },
      "source": [
        "## EDA(탐색적 데이터분석)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhtuTnbiIBP3"
      },
      "source": [
        "# 전체적인 형태 파악\n",
        "train1.head().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYWZvpvkIqkm"
      },
      "source": [
        "# 컬럼 타입 파악\n",
        "train1.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlH3Jd5mxJ6P"
      },
      "source": [
        "### 훈련/검증/테스트 데이터로 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj48Gs9xIkq2"
      },
      "source": [
        "# 전처리\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(train1, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train1[target], random_state=2)\n",
        "\n",
        "\n",
        "train.shape, val.shape, test.shape\n",
        "\n",
        "#stratify : 지정한 Data의 비율을 유지한다. 예를 들어, Label Set인 Y가 25%의 0과 75%의 1로 이루어진 Binary Set일 때,\n",
        "#  stratify=Y로 설정하면 나누어진 데이터셋들도 0과 1을 각각 25%, 75%로 유지한 채 분할된다.\n",
        "\n",
        "# 출처: https://ebbnflow.tistory.com/126 [Dev Log : 삶은 확률의 구름]\n",
        "\n",
        "# ★ stratify: default=None 입니다. classification을 다룰 때 매우 중요한 옵션값입니다. stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해 줍니다. \n",
        "#(한 쪽에 쏠려서 분배되는 것을 방지합니다) 만약 이 옵션을 지정해 주지 않고 classification 문제를 다룬다면, 성능의 차이가 많이 날 수 있습니다.\n",
        "# 계층적 데이터 추출 옵션 (분류 모델에서 추천!)\n",
        "# : 여러 층으로 분할후 각 층별로 렌덤 데이터 추출, 원래 데이터의 분포와 유사하게 데이터 추출\n",
        "#https://teddylee777.github.io/scikit-learn/train-test-split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynre1jKLLetn"
      },
      "source": [
        "train1[target].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVTyXH19K2OX"
      },
      "source": [
        "# 타겟 비율 살펴보기\n",
        "print(train[target].value_counts(normalize=True))\n",
        "print(val[target].value_counts(normalize=True))\n",
        "\n",
        "# stratify=train1[target] -- 이 옵션을 줌으로써 train1의 타겟값 비율이 train과 val에 동일하게 적용되었음을 알 수 있다. \n",
        "# 클래스가 0,1인 분류문제로, 가장 큰 범주(0)dl 76%가량을 차지하고 있다. --> 클래스가 불균형한 분류문제(imbalanced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3b4JUevTbFn"
      },
      "source": [
        "### 프로파일링을 이용한 EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koEYB-WZMm-J"
      },
      "source": [
        "# 프로파일링을 사용해서 데이터리포트를 분석해보자\n",
        "# pip install pandas-profiling   #이 셀안에 글자적으면 실행안됨.\n",
        "\n",
        "\n",
        "# out : SyntaxError: invalid syntax\n",
        "\n",
        "# 설명 : https://github.com/pandas-profiling/pandas-profiling\n",
        "# 공식문서 : https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulkIAosCN-Mb"
      },
      "source": [
        "# pip install -U pandas-profiling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaUofVmELwiA"
      },
      "source": [
        "# from pandas_profiling import ProfileReport\n",
        "# profile = ProfileReport(train).to_notebook_iframe()\n",
        "\n",
        "# #profile = df.profile_report() 이런 형태도 가능\n",
        "# # 좀 더 간략하고 빠르게 보고싶다면  ProfileReport(train, minimal=True) 옵션을 지정한다. --> overview와 Variables까지만 나옴.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ8xbbkqUtl1"
      },
      "source": [
        "# 내보내기\n",
        "# ProfileReport(train).to_file(\"your_report.html\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B--esQQddKV"
      },
      "source": [
        "# warning의 대부분이 결측치에 대한 것임을 알 수 있다. \n",
        "# Impute를 사용할 것을 생각해두자.\n",
        "# dtypes로 하였을 때 실수형이 많았는데, 리포트에는 실수형이 거의 없었다. 어찌된 일인가 알아보자."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkzCrTlHeiGl"
      },
      "source": [
        "## 다시 EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWjkBAdQdpVh"
      },
      "source": [
        "# 실수 형태만 데이터에서 빼내기 : select_dtypes('')\n",
        "train.select_dtypes('float').head(5).T\n",
        "\n",
        "# 실수형이지만, 실제로는 범주형이나 이진형 특성들이구나. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT5ztkawd7Ez"
      },
      "source": [
        "# 중복값도 있는지 알아보자\n",
        "train.T.duplicated()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jg-JLy7dxSU"
      },
      "source": [
        "# 너무 많은 범주 처리:cardinality --> 유일값이 몇개인지 볼 것.\n",
        "train.describe(exclude='number')\n",
        "\n",
        "#exclude='' : 결과에서 생략할 데이터 유형의 블랙리스트. 숫자 유형을 제외하려면 numpy.number를 제출하십시오."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAOgPaxTgE0i"
      },
      "source": [
        "# 디폴트와 비교\n",
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX5WPQKthzbL"
      },
      "source": [
        "train.describe(exclude='number').T.sort_values(by='unique')\n",
        "\n",
        "# state 카디널리티가 너무 높아서 조정을 해줘야겠다..!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuv6umZniJZE"
      },
      "source": [
        "# 카테고리를 많이 가지는 특성의 범주도 살펴보자\n",
        "train['employment_occupation'].value_counts()  #유일값별 갯수세기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1BGBqGbicqJ"
      },
      "source": [
        "## Feature Engneering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heU7GbZKixQX"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def engineer(df):\n",
        "    #높은 카디널리티 제거\n",
        "    selected_cols = df.select_dtypes(include=['number', 'object'])   # df에서 number와 object유형인 feature를 전부 뽑아낸다.(사실 이 데이터에서는 전부다임)\n",
        "    labels = selected_cols.nunique()\n",
        "    selected_features = labels[labels<=30].index.tolist()\n",
        "    df = df[selected_features]\n",
        "\n",
        "    #새로운 특성 생성\n",
        "    #컬럼에서 behavioral 관련 특성 뽑아서 합계한 하나의 특성을 만들기\n",
        "    behaviorals = [col for col in df.columns if 'behavioral' in col]\n",
        "    df['behaviorals'] = df[behaviorals].sum(axis=1)\n",
        "\n",
        "    #seas 컬럼은 제거\n",
        "    dels = [col for col in df.columns if ('employment' in col or 'seas' in col)]\n",
        "    df.drop(columns=dels, inplace = True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# train = engineer(train)\n",
        "# val = engineer(val)\n",
        "# teste = engineer(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htXIUH07mMde"
      },
      "source": [
        "### 피쳐엔지니어링 연습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSt4lT5vkbAK"
      },
      "source": [
        "#1) nunique()  vs .unique()\n",
        "labels1 = train.nunique()  #nunique()는 컬럼별로 유일값 갯수를 세어주는 것.\n",
        "labels1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w7ROIe7kFb8"
      },
      "source": [
        "train['employment_occupation'].unique()\n",
        "\n",
        "# unique()는 어레이배열에서 유일값을 빼주는 것.\n",
        "# 만약 어레이 배열에서 유일값 갯수를 세고싶다면 value_counts() 메서드를 써야 한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vUOnMqwk48V"
      },
      "source": [
        "#2) \n",
        "labels1[labels1 <=30]  #state가 빠짐."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrWOGhH-lEw0"
      },
      "source": [
        "select = labels1[labels1 <=30].index # 유일값이 30보다 작은 것만 뽑아서, 어레이 배열의 인덱스를 꺼낸다. \n",
        "select"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6wL-7E9lOM5"
      },
      "source": [
        "# 그걸 다시 list로 만든다 ★ 굳이 왜 만든건지 모르겠넹\n",
        "select1 = labels1[labels1 <=30].index.tolist()\n",
        "select1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRXNf-3WlmDL"
      },
      "source": [
        "train_sl=train[select1]\n",
        "train_sl.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSDpmaHCqk1G"
      },
      "source": [
        "a=[]\n",
        "for col in train_sl.columns:\n",
        "    if 'behavioral' in col :\n",
        "        a.append(col)\n",
        "    \n",
        "print(a)\n",
        "\n",
        "# --> 축약하면\n",
        "# --> [col for col in train_sl.columns if 'behivioral' in col]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrGD_PBcsn4d"
      },
      "source": [
        "train_sl[a].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GggsOHdDtDf7"
      },
      "source": [
        "train_sl[a].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35BAVj99tH4V"
      },
      "source": [
        "train_sl[a].sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOdDwOFtmACC"
      },
      "source": [
        "train[select].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HENimYu-xtJk"
      },
      "source": [
        "### 연습 끝!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A70jUk_kLtc"
      },
      "source": [
        "# 함수 적용해서 특성공학 완료\n",
        "train = engineer(train)\n",
        "val = engineer(val)\n",
        "test = engineer(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsgFOAGywUQf"
      },
      "source": [
        "## 특성/타겟 분리하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3PGxJC4wdAQ"
      },
      "source": [
        "target = 'vacc_h1n1_f'\n",
        "features = train.drop(columns = [target]).columns\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Hhw2kKyHxb"
      },
      "source": [
        "## Pipelines : 전처리+모델링(LogisticRegression)\n",
        "- 중복코드의 최소화로 여러 모델을 같은 전처리 프로세스에 연결시킨다.\n",
        "- 그리드서치(grid search)를 통해 여러 하이퍼파라미터를 쉽게 연결가능.(★??)\n",
        "\n",
        "전처리: OneHotEncoder(),     SimpleImputer(),    StandardScaler(),\n",
        "\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icHIGUay7uz"
      },
      "source": [
        "pip install --upgrade category_encoders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hce5Tovt047h"
      },
      "source": [
        "# 파이프라인에 넣어도 다 import해 줘야됨 \n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhmqQEyfzA2N"
      },
      "source": [
        "pipe = make_pipeline(\n",
        "    OneHotEncoder(),\n",
        "    SimpleImputer(),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(n_jobs=-1)\n",
        ")\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "print('검증세트 정확도', pipe.score(X_val,y_val))  #변환을 적용하고 최종 추정기로 점수를 매깁니다.(predict까지 들어가있음)\n",
        "\n",
        "y_pred = pipe.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViiHRUBmzhyc"
      },
      "source": [
        "n_jobs=-1\n",
        "\n",
        "n_jobs = int, default=None\n",
        "Number of CPU cores used when parallelizing over classes if multi_class=’ovr’”. This parameter is ignored when the solver is set to ‘liblinear’ regardless of whether ‘multi_class’ is specified or not. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf3BclNN2Vs6"
      },
      "source": [
        "### 파이프라인 스텝접근\n",
        "\n",
        "- named_steps 은 유사 딕셔너리 객체(dictionary-like object)로 파이프라인 내 과정에 접근 가능하도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmy64-J2Gqs"
      },
      "source": [
        "# 파이프라인에서 각 스텝에 접근하기\n",
        "# https://scikit-learn.org/stable/modules/compose.html#accessing-steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcZed7az2Mvi"
      },
      "source": [
        "pipe.named_steps #각 스텝에 접근하게 해주는 메서드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R1wvy3423q7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "enc = pipe.named_steps['onehotencoder']\n",
        "encoded_columns = enc.transform(X_val).columns #원핫인코딩한 범주형 칼럼을 뺴내고..\n",
        "\n",
        "model_lr = pipe.named_steps['logisticregression'] \n",
        "coefficients = pd.Series(model_lr.coef_[0], encoded_columns) # 인덱스를 아까빼낸 칼럼에서 가져오고, 로지스틱회귀의 계수를 빼내서 시리즈로 만들자.\n",
        "\n",
        "plt.figure(figsize=(10,30))\n",
        "coefficients.sort_values().plot.barh();  #만든 시리즈를 값이 계수가 큰 순서대로 정렬해서, 수평plot으로 만들어\n",
        "\n",
        "# 0이 아무 상관관계도 없는거. -는 음의 상관관계, +는 양의 상관관계.\n",
        "# 상관계수 해석 : https://ko.wikipedia.org/wiki/%EC%83%81%EA%B4%80_%EB%B6%84%EC%84%9D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-819KLF40Xg"
      },
      "source": [
        "# Decision Tree 드디어 결정트리의 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orAT2aex49Up"
      },
      "source": [
        "모델의 종류\n",
        "- distance-based model    vs    rule-based model\n",
        "- distance : 거리. error를 기준으로 하는 모델. (다양한 회귀모델이 이에 해당)\n",
        "- rule : 하나의 노드 지날 때마다 룰1, 룰2...\n",
        "- 결정트리 학습 = 노드를 어떻게 분할하는가에 대한 문제.\n",
        "- 트리모델 학습 알고리즘 = 결정트리의 비용함수를 최소화하도록 분할하는 것. \n",
        "\n",
        "- 특성들을 기준으로 샘플을 분류하는데, 그 형태가 나무가지가 뻗어나가는 모습과 비슷해서 결정트리라고 불림. 스무고개하듯 특성들의 수치를 가지고 질문을 통해 정답 클래스를 찾아가는 과정이다. 데이터를 분할해가는 알고리즘.\n",
        "\n",
        "- 말단의 정답을 노드(node)\n",
        "- 노드를 연결하는 선을 엣지(edge)\n",
        "- root노드, internal노드, leaf/external, terminal노트로 나뉜다. (뿌리, 중간, 말단)\n",
        "\n",
        "- 분류, 회귀 모두 적용가능\n",
        "- 새로운 데이터가 특정 말단 노트에 속한다는 정보를 확인한 뒤, 말단 노트의 빈도가 가장 높은 범주로 데이터 분류.(★)\n",
        "- 앙상블 기법 : 랜더포레스트, 그레디언트부스팅트리\n",
        "\n",
        "- 장점 : 직관적인 해석이 가능\n",
        "- 단점 : 과적합.\n",
        "\n",
        "- 하나의 노드안에 2개의 질문이 들어갈 수 없다. 한 특성에 대해서만 분류 가능\n",
        "- 트리결정에서는 다중공선성 영향을 많이 받지는 않지만 전처리는 완벽해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDmHA1rd9bgo"
      },
      "source": [
        "## 비용함수 : 지니불순도, 엔트로피\n",
        "- 지니불순도(Gini Impurity or Gini Index): \n",
        "\n",
        "$${\\displaystyle {I}_{G}(p)=\\sum _{i=1}^{J}p_{i}(1-p_{i})=1-\\sum _{i=1}^{J}{p_{i}}^{2}}$$\n",
        "\n",
        "\n",
        "- 엔트로피(Entropy):\n",
        " \n",
        "$${\\displaystyle \\mathrm {H} (T)=\\operatorname {I} _{E}\\left(p_{1},p_{2},...,p_{J}\\right)=-\\sum _{i=1}^{J}{p_{i}\\log _{2}p_{i}}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smBSZayx9uSp"
      },
      "source": [
        "가지를 어떻게 치니? : 엔트로피 또는 지니불순도로 친다. 엔트로피가 최고 높을 떄가 50:50\n",
        " \n",
        "d얼마나 탁하냐. \n",
        "feature importance : 타겟에 중요한 역할을 하는 피쳐를 순서대로 나타낸 것.\n",
        " \n",
        "결정트리는 information gain이 최대화되는 방식으로 나눠줌 : 불순도가 감소했다 --> 임폴메이션 게인을 얻었다. 최대가 되는 방식으로 디시즌트리를 만들어감.\n",
        "\n",
        "엔트로피가 조금 더 균형잡힌 트리를 만들지만 지니불순도가 계산이 조금 더 빨라서 디폴트로 씀."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqBXMJIp9BPL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}