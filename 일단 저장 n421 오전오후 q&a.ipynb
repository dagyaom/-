{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSbwDN/lD0+aELK+RVaHYA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dagyeom23658/Python_Practice/blob/main/%EC%9D%BC%EB%8B%A8%20%EC%A0%80%EC%9E%A5%20n421%20%EC%98%A4%EC%A0%84%EC%98%A4%ED%9B%84%20q%26a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZyxrUwMQyq_"
      },
      "source": [
        "정규표현식이랑 불용어 사전에 단어 추가 함께 썼다가 세션다운됐는데, "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Eia5LiQzSz"
      },
      "source": [
        "불용어 : 모든 문서에 등장한다. tf-idf --> 낮게 나온다. 불용어 처리할 필요성이 줄어든다. \n",
        "\n",
        "ngram_range\n",
        "- Ngram\n",
        "\n",
        "자연어처리 기술 발전 흐름은 \"언어가 갖고 있는 정보가 많이 포함되고, 표현되게끔\"\n",
        "\n",
        "1. 규칙기반 자연어처리\n",
        "- 모든 언어규칙을 하드코딩한다.\n",
        "- 단점 : 언어 규칙에는 예외가 존재, 시간이 오래 걸린다. \n",
        "언어학 도메인 전문가가 매우 중요하다. \n",
        "\n",
        "2. 통계 기반\n",
        "- 언어 분포가 존재. \n",
        "- Bow : 단순 빈도( 카운트 기반)\n",
        "    -단점 : 불용어에 취약하다.  단순등장 빈도수가 의미적 중요성을 나타내지 못한다. 문맥을 고려하지 못한다. \n",
        "    - ngram : 같이 등장하는 단어들의 묶음 -> bow에 비해 단어 연관성, 단어 간 조합, 특정 범위 내에 같이 자주 등장하는 정보가 포함된다. -> 동시 등장 빈도라는 새로운 정보가 추가됨.\n",
        "    - tf-idf : 추가되는 새로운 정보들이 포함된다. \n",
        "    \n",
        "\n",
        "    단어 간 순서가 중요?\n",
        "    -> 단어 간 순서정보를 포함하고 싶다.!!!!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAfCXqHlaFUI"
      },
      "source": [
        "원형을 찾기 위해\n",
        "1. 어간 추출\n",
        "- wolves -> wolv\n",
        "- 장점 : 시간/속도, 새로운 단어가 만들어진다. (장점이자 단점이다. 피쳐수가 증가함..!! --> 의미정보가 남아있다.)\n",
        "- 단점 : 헷갈린다. \n",
        "\n",
        "2. 표제어 추출\n",
        "- wolves -> wolf\n",
        "- 단점 : 시간이 느리다. --> \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMrL9b2HaEcy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68z0j9zWWCxY"
      },
      "source": [
        "오전에 필기 했던거 공유 드려보아요... ! \n",
        "\n",
        "오전 QA\n",
        "NLP API를 제공하는 service provider, 주로 클라우드 플랫폼을 제공 (구글, 네이버, 카카오 등.)\n",
        "\n",
        "| NLP 발전 흐름 : “언어가 갖고 있는 다양한 정보를 최대한 많이 포함하게끔 발전”\n",
        ">초기 NLP \n",
        "1970-1980 자연어 처리 : 규칙 기반 자연어 처리 (모든 문법을 하드코딩)\n",
        "*문법에 예외가 너무 많기 때문에 이러한 예외를 모두 하드 코딩할 수는 없음. \n",
        "\n",
        ">통계적 접근 (bow, td-idf) \n",
        "*bow (문서에 등장하는 단어의 빈도수를 중요도라고 가정하고 단어의 빈도를 바탕으로 \n",
        "*td-idf (문서의 불용어에 가중치를 주는 방향으로 보완)\n",
        "(구글의 검색엔진 결과 최적화 등에 많이 사용, 유사도를 계산)\n",
        "(문서 간의 유사도를 같이 따져보지 않으면 유사한 문서끼리 있을 때 오히려 중요도가 잘못 오인될 수 있음)\n",
        "\n",
        "분포 기반의 접근 \n",
        "\n",
        "| 텍스트 전처리\n",
        ">불용어(Stop Words) 처리\n",
        "*불용어 기준이 문제에 따라 다를 수 있다. (주관적이다)\n",
        "*tf-idf 와 같이 불용어에 가중치를 주는 경우 라면 상대적으로 덜 필요하다\n",
        "\n",
        ">통계적 트리밍(trimming) : 너무 많거나 너무 적은 단어들을 배제\n",
        "*min_freq 로 간단하게 단어 빈도수를 요약해서 볼 수도 있을 것\n",
        "(Tensorflow, pytorch 모두 입력한 해당 빈도를 바탕으로 자동 삭제시킬 수도 있음)\n",
        "\n",
        ">어간 추출(Stemming) 혹은 표제어 추출(Lemmatization):\n",
        "*한국어의 경우 형태소 분석을 바탕으로 어간 추출, 표제어 추출을 진행.\n",
        "\n",
        "텍스트 전처리 외에도 일반 전처리 및 데이터 시각화 함수로 정리 해놓고 사용해보자"
      ]
    }
  ]
}